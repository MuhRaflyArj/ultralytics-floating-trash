{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'datasets', 'AblationDataset', 'flow', 'flow.yaml')\n",
    "test_data_path = os.path.join(os.getcwd(), 'datasets', 'TestDataset', 'flowtest', 'flowtest.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='s'.\n",
      "New https://pypi.org/project/ultralytics/8.3.104 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96 üöÄ Python-3.10.16 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080, 9994MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo12-cbam-a.yaml, data=coco.yaml, epochs=300, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=yolo12-coco, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ai-laboratory/Documents/ultralytics-floating-trash/runs/detect/yolo12-coco\n",
      "\n",
      "Dataset 'coco.yaml' images not found ‚ö†Ô∏è, missing path '/home/ai-laboratory/Documents/datasets/coco/val2017.txt'\n",
      "Downloading https://ultralytics.com/assets/coco2017labels-segments.zip to '/home/ai-laboratory/Documents/datasets/coco2017labels-segments.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 169M/169M [00:04<00:00, 36.6MB/s] \n",
      "Unzipping /home/ai-laboratory/Documents/datasets/coco2017labels-segments.zip to /home/ai-laboratory/Documents/datasets/coco...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122232/122232 [00:06<00:00, 17785.34file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://images.cocodataset.org/zips/train2017.zip to '/home/ai-laboratory/Documents/datasets/coco/images/train2017.zip'...\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip to '/home/ai-laboratory/Documents/datasets/coco/images/val2017.zip'...\n",
      "Downloading http://images.cocodataset.org/zips/test2017.zip to '/home/ai-laboratory/Documents/datasets/coco/images/test2017.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success ‚úÖ (1526.9s), saved to \u001b[1m/home/ai-laboratory/Documents/datasets\u001b[0m\n",
      "\n",
      "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='s'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
      "  9                  -1  1    262754  ultralytics.nn.modules.conv.CBAM             [512]                         \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n",
      " 13                  -1  1     65890  ultralytics.nn.modules.conv.CBAM             [256]                         \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n",
      " 17                  -1  1     16610  ultralytics.nn.modules.conv.CBAM             [128]                         \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22                  -1  1     65890  ultralytics.nn.modules.conv.CBAM             [256]                         \n",
      " 23             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 25        [16, 20, 24]  1    850368  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLO12-cbam-a summary: 292 layers, 9,695,240 parameters, 9,695,224 gradients, 22.0 GFLOPs\n",
      "\n",
      "Freezing layer 'model.25.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ai-laboratory/Documents/datasets/coco/labels/train2017... 117266 images, 1021 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 118287/118287 [01:08<00:00, 1724.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/ai-laboratory/Documents/datasets/coco/labels/train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ai-laboratory/Documents/datasets/coco/labels/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:02<00:00, 2201.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/ai-laboratory/Documents/datasets/coco/labels/val2017.cache\n",
      "Plotting labels to /home/ai-laboratory/Documents/ultralytics-floating-trash/runs/detect/yolo12-coco/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 113 weight(decay=0.0), 128 weight(decay=0.0005), 123 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/ai-laboratory/Documents/ultralytics-floating-trash/runs/detect/yolo12-coco\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300      6.72G      2.969      4.898      3.399        243        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7393/7393 [20:47<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:18<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      36335      0.394     0.0481     0.0252     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/300      8.22G      1.983      3.682      2.233        181        640:   1%|          | 47/7393 [00:07<20:23,  6.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo12-cbam-a.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoco.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myolo12-coco\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/engine/model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/engine/trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/engine/trainer.py:384\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[1;32m    383\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/tasks.py:291\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m--> 291\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/tasks.py:115\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/tasks.py:133\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/tasks.py:154\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 154\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    155\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/modules/head.py:70\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_end2end(x)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[0;32m---> 70\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ultralytics-floating-trash/ultralytics/nn/modules/conv.py:79\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = YOLO('yolo12-cbam-a.yaml')\n",
    "model.train(\n",
    "    data='coco.yaml',\n",
    "    epochs=300,\n",
    "    batch=16,\n",
    "    imgsz=640,\n",
    "    name='yolo12-coco', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.96 üöÄ Python-3.10.16 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080, 9994MiB)\n",
      "YOLOv12s summary (fused): 159 layers, 9,231,267 parameters, 0 gradients, 21.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ai-laboratory/Documents/ultralytics-floating-trash/datasets/TestDataset/flowtest/test/labels.cache... 800 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800/800 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:02<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        800       2022      0.831      0.784      0.838       0.42\n",
      "Speed: 0.1ms preprocess, 2.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ai-laboratory/Documents/ultralytics-floating-trash/runs/detect/yolo12-pt-testing2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7db2d8d52710>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,\n",
       "            0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99563,     0.99231,     0.99231,\n",
       "            0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99231,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,\n",
       "            0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,\n",
       "            0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,\n",
       "            0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.99031,     0.98853,     0.98853,     0.98853,     0.98853,\n",
       "            0.98853,     0.98853,     0.98853,     0.98853,     0.98853,     0.98853,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,\n",
       "             0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,      0.9881,     0.98672,     0.98672,     0.98672,     0.98672,     0.98672,     0.98672,\n",
       "            0.98672,     0.98672,     0.98672,     0.98672,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98582,     0.98492,\n",
       "            0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98492,     0.98382,     0.98382,     0.98382,     0.98382,     0.98382,     0.98382,     0.98382,     0.98382,\n",
       "            0.98382,     0.98382,     0.98251,     0.98251,     0.98251,     0.98251,     0.98251,     0.98142,     0.98142,     0.98142,     0.98142,     0.98142,     0.98142,     0.98142,     0.98142,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,\n",
       "             0.9808,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,      0.9808,     0.97944,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,\n",
       "             0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,      0.9794,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,\n",
       "            0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,     0.97935,      0.9784,      0.9784,      0.9784,      0.9784,      0.9784,      0.9784,     0.97724,     0.97669,     0.97669,     0.97669,     0.97669,     0.97669,     0.97669,     0.97669,     0.97669,     0.97669,\n",
       "            0.97669,     0.97669,     0.97669,     0.97576,     0.97576,     0.97576,     0.97576,      0.9747,      0.9747,     0.97359,     0.97275,     0.97275,     0.97275,     0.97275,     0.97275,       0.972,       0.972,       0.972,       0.972,       0.972,       0.972,     0.96984,     0.96984,\n",
       "            0.96886,     0.96886,     0.96686,     0.96686,     0.96579,     0.96493,     0.96493,     0.96493,     0.96396,       0.963,       0.963,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,     0.96192,\n",
       "            0.96133,     0.96133,     0.96133,     0.96133,     0.96133,     0.96133,     0.96051,     0.96051,     0.95962,     0.95962,     0.95789,     0.95789,     0.95789,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,\n",
       "            0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95776,     0.95699,\n",
       "            0.95699,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,     0.95594,      0.9542,      0.9517,      0.9517,     0.95111,     0.95111,     0.95111,     0.95111,     0.95111,     0.95111,     0.95111,     0.95111,     0.95111,\n",
       "            0.95111,     0.95111,     0.95111,     0.95111,     0.94945,     0.94876,     0.94876,     0.94718,     0.94641,     0.94599,     0.94599,     0.94599,     0.94599,     0.94599,     0.94558,     0.94558,     0.94558,     0.94558,     0.94499,     0.94499,     0.94499,     0.94464,     0.94464,\n",
       "            0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94464,     0.94392,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,      0.9436,\n",
       "             0.9436,      0.9436,     0.94329,     0.94329,     0.94329,     0.94329,     0.94329,     0.94191,     0.94191,     0.94118,     0.93972,     0.93868,     0.93868,     0.93868,     0.93868,     0.93868,     0.93821,     0.93821,     0.93821,      0.9378,      0.9378,      0.9378,     0.93735,\n",
       "            0.93735,     0.93735,     0.93735,     0.93735,     0.93735,     0.93735,     0.93735,     0.93735,     0.93735,     0.93691,     0.93691,     0.93691,     0.93627,     0.93559,     0.93468,     0.93468,     0.93468,     0.93468,     0.93468,     0.93333,     0.93333,     0.93333,     0.93333,\n",
       "            0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93333,     0.93308,     0.93308,     0.93308,     0.93308,     0.93308,     0.93248,     0.93189,     0.93139,     0.93139,     0.93016,     0.92968,     0.92968,\n",
       "             0.9291,     0.92847,     0.92685,     0.92685,     0.92685,     0.92622,     0.92498,     0.92375,     0.92324,      0.9228,      0.9228,      0.9228,      0.9228,      0.9228,      0.9228,      0.9228,      0.9228,     0.92176,     0.92176,     0.92176,     0.92135,     0.92135,     0.92135,\n",
       "            0.92135,     0.92135,     0.92135,     0.92135,     0.92135,     0.92087,     0.91969,     0.91922,     0.91922,     0.91811,     0.91753,      0.9173,      0.9173,      0.9173,     0.91684,     0.91684,     0.91575,     0.91542,     0.91542,     0.91542,     0.91434,     0.91322,     0.91173,\n",
       "            0.91173,     0.91173,     0.91135,     0.91135,     0.91043,     0.91043,     0.91006,     0.91006,     0.90969,     0.90969,     0.90861,     0.90807,     0.90771,     0.90771,     0.90724,     0.90623,     0.90517,     0.90476,     0.90476,     0.90371,      0.9035,      0.9035,      0.9035,\n",
       "            0.90252,     0.90212,     0.90212,     0.90058,     0.89719,     0.89618,     0.89517,     0.89424,     0.89374,     0.89274,     0.89252,     0.89252,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89151,     0.89116,     0.88985,\n",
       "            0.88985,     0.88985,     0.88889,     0.88848,      0.8876,     0.88665,     0.88618,     0.88578,     0.88545,     0.88506,     0.88459,      0.8842,     0.88415,     0.88415,     0.88415,     0.88383,     0.88383,     0.88239,       0.882,     0.88057,     0.87766,     0.87721,     0.87581,\n",
       "            0.87544,     0.87522,     0.87522,     0.87332,     0.87194,      0.8706,      0.8706,      0.8706,      0.8706,     0.87039,     0.87039,     0.86997,     0.86912,     0.86835,      0.8675,     0.86519,     0.86271,     0.86271,     0.86271,     0.86205,     0.86205,     0.86172,     0.86043,\n",
       "            0.85866,     0.85842,     0.85714,     0.85493,     0.85171,     0.85149,     0.85071,     0.85033,     0.84825,     0.84749,     0.84574,     0.84544,     0.84378,     0.84259,     0.84095,     0.83751,     0.83751,     0.83751,     0.83732,     0.83732,     0.83589,     0.83589,     0.83439,\n",
       "            0.83377,     0.83377,     0.83089,     0.82917,     0.82917,     0.82839,     0.82771,     0.82669,     0.82636,      0.8245,     0.82097,     0.81897,     0.81749,     0.81437,     0.80924,     0.80781,     0.80558,     0.80258,     0.80119,     0.79784,     0.79491,     0.79019,     0.78952,\n",
       "            0.78592,     0.78462,     0.78294,     0.77905,     0.77889,     0.77799,     0.77794,     0.77631,     0.77568,     0.77371,     0.76959,     0.76945,     0.76186,     0.76033,     0.75467,      0.7542,     0.75238,     0.75056,     0.74309,     0.74013,     0.73246,     0.73013,     0.72656,\n",
       "            0.72397,     0.72141,     0.71838,     0.71758,     0.71386,     0.71211,     0.70937,     0.70488,     0.69556,     0.69382,     0.67934,     0.67582,     0.66995,     0.66628,     0.66628,     0.66524,     0.66446,     0.66113,     0.65457,      0.6511,     0.64866,     0.64551,     0.64288,\n",
       "            0.64267,     0.63048,     0.61372,     0.60988,     0.59356,     0.59086,     0.57969,     0.57195,     0.56206,     0.55095,     0.54418,     0.54008,      0.5354,     0.52776,      0.5068,     0.50316,     0.49395,     0.46128,     0.42777,     0.42291,     0.41976,     0.41354,     0.40565,\n",
       "            0.38845,      0.3819,     0.37882,     0.37574,     0.37266,     0.36958,      0.3665,     0.36342,     0.36034,     0.35726,     0.35418,      0.3511,     0.34802,     0.34494,     0.34186,     0.33878,      0.3357,     0.33262,     0.32954,     0.32646,     0.32338,      0.3203,     0.31722,\n",
       "            0.31414,     0.31106,     0.30798,      0.3049,     0.30182,     0.29874,     0.29566,     0.29258,      0.2895,     0.28642,     0.28334,     0.28026,     0.27718,      0.2741,     0.27102,     0.26794,     0.26486,     0.26178,      0.2587,     0.25562,     0.25254,     0.24946,     0.24638,\n",
       "             0.2433,     0.24022,     0.23714,     0.23406,     0.23099,     0.22791,     0.22483,     0.22175,     0.21867,     0.21559,     0.21251,     0.20943,     0.20635,     0.20327,     0.20019,     0.19711,     0.19403,     0.19095,     0.18787,     0.18479,     0.18171,     0.17863,     0.17555,\n",
       "            0.17247,     0.16939,     0.16631,     0.16323,     0.16015,     0.15707,     0.15399,     0.15091,     0.14783,     0.14475,     0.14167,     0.13859,     0.13551,     0.13243,     0.12935,     0.12627,     0.12319,     0.12011,     0.11703,     0.11395,     0.11087,     0.10779,     0.10471,\n",
       "            0.10163,    0.098554,    0.095474,    0.092394,    0.089314,    0.086234,    0.083155,    0.080075,    0.076995,    0.073915,    0.070835,    0.067756,    0.064676,    0.061596,    0.058516,    0.055436,    0.052357,    0.049277,    0.046197,    0.043117,    0.040037,    0.036958,    0.033878,\n",
       "           0.030798,    0.027718,    0.024638,    0.021559,    0.018479,    0.015399,    0.012319,   0.0092394,   0.0061596,   0.0030798,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.53329,     0.53329,      0.5928,     0.62854,     0.65167,     0.66538,     0.67754,     0.68909,     0.69807,     0.70394,     0.71189,     0.71553,      0.7202,      0.7253,     0.72931,     0.73229,     0.73366,      0.7362,     0.73848,     0.74134,     0.74362,     0.74362,     0.74562,\n",
       "             0.7479,     0.75003,     0.75231,     0.75475,     0.75734,     0.75979,     0.76106,     0.76233,     0.76312,     0.76453,     0.76551,     0.76716,     0.76722,     0.76794,     0.76781,      0.7685,     0.76977,     0.77012,     0.77042,     0.77096,     0.77125,     0.77223,     0.77275,\n",
       "            0.77367,     0.77491,     0.77552,     0.77578,     0.77622,     0.77662,     0.77707,      0.7781,     0.77901,     0.77948,     0.78025,     0.78125,     0.78129,     0.78142,     0.78261,     0.78276,     0.78334,     0.78389,     0.78393,     0.78503,     0.78511,     0.78545,     0.78545,\n",
       "            0.78612,      0.7856,     0.78596,     0.78643,     0.78719,     0.78748,     0.78807,     0.78791,     0.78814,     0.78841,     0.78868,     0.78883,     0.78928,     0.78941,      0.7903,     0.79081,     0.79165,     0.79219,     0.79223,     0.79192,     0.79193,      0.7921,     0.79289,\n",
       "            0.79309,     0.79365,     0.79333,     0.79395,     0.79434,       0.794,      0.7948,     0.79415,     0.79388,      0.7936,     0.79352,     0.79377,     0.79389,     0.79414,     0.79442,     0.79457,     0.79512,     0.79541,     0.79517,     0.79532,     0.79512,     0.79527,     0.79528,\n",
       "            0.79567,     0.79551,     0.79565,     0.79582,     0.79578,     0.79614,     0.79657,     0.79694,     0.79715,     0.79692,     0.79714,     0.79716,     0.79709,     0.79711,     0.79759,      0.7977,      0.7978,     0.79796,     0.79819,     0.79834,     0.79867,     0.79892,      0.7994,\n",
       "            0.79961,     0.79984,     0.79994,      0.8003,     0.80062,     0.80113,     0.80122,     0.80103,     0.80113,     0.80107,       0.801,     0.80093,     0.80092,     0.80097,     0.80103,     0.80112,     0.80121,     0.80113,     0.80105,     0.80123,     0.80113,     0.80137,     0.80186,\n",
       "            0.80199,     0.80212,     0.80235,     0.80259,     0.80286,     0.80259,     0.80287,     0.80279,     0.80243,     0.80248,     0.80253,     0.80258,     0.80305,     0.80292,     0.80335,     0.80382,     0.80396,     0.80406,     0.80451,     0.80465,      0.8048,     0.80508,     0.80501,\n",
       "            0.80535,     0.80547,     0.80558,      0.8057,     0.80609,     0.80625,     0.80622,     0.80604,     0.80614,       0.806,      0.8061,      0.8063,     0.80641,     0.80627,     0.80681,     0.80687,     0.80664,     0.80671,      0.8067,     0.80715,     0.80749,     0.80754,     0.80759,\n",
       "            0.80764,     0.80793,     0.80794,     0.80788,     0.80801,     0.80811,     0.80812,     0.80793,     0.80804,     0.80825,     0.80807,     0.80817,     0.80799,     0.80749,      0.8076,     0.80783,     0.80758,     0.80748,     0.80748,     0.80731,     0.80738,     0.80746,     0.80756,\n",
       "            0.80669,     0.80688,     0.80666,     0.80675,      0.8069,     0.80718,     0.80694,     0.80699,     0.80707,     0.80715,     0.80721,     0.80727,     0.80733,     0.80724,     0.80746,     0.80751,     0.80755,      0.8076,     0.80764,     0.80798,     0.80746,     0.80716,     0.80733,\n",
       "            0.80728,     0.80721,     0.80725,     0.80711,     0.80726,      0.8074,     0.80725,     0.80708,      0.8069,     0.80632,     0.80647,     0.80658,       0.807,     0.80636,     0.80593,     0.80558,     0.80484,     0.80476,     0.80469,     0.80462,     0.80455,     0.80455,      0.8046,\n",
       "            0.80465,     0.80469,     0.80477,     0.80491,     0.80554,     0.80564,     0.80573,     0.80559,     0.80578,     0.80578,     0.80593,       0.806,     0.80614,     0.80616,     0.80618,     0.80592,     0.80599,     0.80611,     0.80582,     0.80591,       0.806,     0.80627,     0.80653,\n",
       "            0.80659,     0.80643,     0.80624,     0.80604,     0.80626,     0.80629,     0.80597,     0.80602,     0.80617,     0.80652,     0.80636,     0.80599,     0.80594,      0.8061,     0.80622,     0.80612,     0.80602,     0.80586,     0.80542,     0.80539,     0.80529,      0.8055,     0.80586,\n",
       "            0.80638,     0.80651,     0.80658,     0.80665,     0.80634,     0.80618,     0.80612,     0.80636,     0.80661,     0.80681,     0.80699,     0.80655,     0.80667,     0.80696,     0.80702,     0.80708,     0.80709,     0.80694,     0.80677,     0.80649,     0.80625,     0.80604,     0.80593,\n",
       "            0.80582,     0.80583,     0.80593,     0.80604,     0.80618,     0.80662,     0.80652,     0.80642,     0.80632,     0.80611,     0.80639,     0.80647,     0.80654,      0.8066,     0.80638,     0.80626,      0.8062,     0.80614,     0.80608,     0.80602,     0.80615,     0.80588,     0.80525,\n",
       "            0.80504,     0.80521,     0.80529,     0.80537,     0.80481,     0.80454,     0.80437,     0.80424,     0.80404,     0.80397,     0.80426,     0.80435,     0.80444,     0.80433,     0.80471,      0.8047,     0.80462,     0.80453,     0.80447,     0.80487,     0.80506,     0.80477,     0.80515,\n",
       "            0.80506,     0.80497,     0.80489,     0.80487,     0.80493,     0.80483,     0.80474,     0.80458,     0.80445,     0.80425,     0.80433,      0.8044,     0.80435,     0.80425,     0.80395,     0.80377,     0.80338,     0.80292,     0.80305,     0.80264,     0.80209,     0.80189,     0.80154,\n",
       "            0.80139,     0.80128,     0.80111,     0.80069,     0.80065,     0.80058,     0.80092,     0.80103,     0.80092,     0.80081,     0.80089,     0.80071,     0.80086,     0.80099,     0.80102,     0.80089,     0.80077,     0.80053,     0.80077,     0.80105,     0.80115,     0.80082,     0.80021,\n",
       "            0.80007,      0.8001,     0.79981,     0.79963,     0.79962,     0.79922,     0.79943,     0.79963,     0.79968,     0.79955,     0.79908,     0.79914,     0.79921,     0.79943,     0.79916,     0.79921,     0.79926,      0.7993,     0.79935,     0.79973,     0.79997,      0.7998,     0.79977,\n",
       "            0.79988,     0.79947,     0.79953,     0.79926,     0.79897,     0.79915,     0.79872,     0.79819,     0.79781,     0.79706,     0.79666,      0.7966,     0.79672,     0.79619,     0.79601,      0.7961,     0.79619,     0.79568,     0.79518,     0.79493,     0.79491,     0.79449,     0.79447,\n",
       "            0.79436,     0.79404,      0.7939,     0.79391,     0.79369,     0.79364,     0.79316,     0.79311,     0.79309,     0.79279,     0.79287,     0.79266,     0.79194,     0.79142,     0.79162,      0.7919,     0.79151,     0.79117,     0.79111,     0.79085,     0.78997,     0.78935,     0.78885,\n",
       "            0.78811,      0.7879,      0.7876,     0.78665,     0.78603,     0.78552,     0.78573,      0.7857,     0.78582,     0.78598,     0.78591,     0.78536,     0.78511,     0.78485,     0.78463,     0.78448,     0.78445,     0.78432,     0.78419,     0.78434,     0.78408,     0.78389,     0.78367,\n",
       "            0.78346,     0.78362,       0.783,     0.78308,     0.78316,     0.78333,     0.78323,     0.78328,     0.78305,     0.78307,     0.78373,     0.78398,     0.78314,     0.78372,     0.78299,     0.78291,     0.78274,     0.78239,     0.78217,     0.78234,       0.782,     0.78165,     0.78147,\n",
       "             0.7811,     0.78091,     0.78079,     0.78062,      0.7805,     0.78029,     0.78035,      0.7802,      0.7803,      0.7798,     0.77942,     0.77945,     0.77901,     0.77916,     0.77889,     0.77868,     0.77875,     0.77858,     0.77846,     0.77859,     0.77825,     0.77808,     0.77811,\n",
       "            0.77728,     0.77695,     0.77669,     0.77635,     0.77642,     0.77599,      0.7753,     0.77464,     0.77424,     0.77398,     0.77323,     0.77312,       0.773,     0.77299,     0.77283,     0.77198,     0.77174,     0.77169,     0.77138,     0.77103,     0.77081,     0.77002,     0.76977,\n",
       "            0.77012,      0.7703,     0.76971,     0.77003,      0.7691,      0.7691,     0.76827,     0.76737,     0.76731,     0.76702,     0.76631,      0.7661,     0.76589,     0.76477,     0.76414,     0.76395,     0.76336,     0.76354,     0.76342,     0.76326,     0.76314,     0.76242,     0.76188,\n",
       "            0.76201,     0.76214,     0.76141,     0.76072,     0.76031,     0.75888,     0.75782,     0.75716,     0.75645,     0.75622,     0.75593,     0.75515,     0.75436,     0.75463,     0.75435,     0.75371,     0.75133,      0.7507,     0.75046,     0.74958,     0.74928,     0.74948,     0.74937,\n",
       "            0.74924,     0.74921,     0.74905,     0.74778,     0.74802,     0.74747,     0.74783,     0.74767,     0.74751,     0.74696,      0.7467,     0.74621,     0.74533,     0.74525,     0.74473,     0.74365,     0.74309,     0.74198,     0.74137,     0.74079,     0.74039,     0.73986,     0.73889,\n",
       "            0.73863,     0.73808,      0.7374,     0.73721,     0.73625,     0.73481,     0.73382,     0.73248,     0.73133,     0.73084,     0.72871,     0.72774,     0.72702,     0.72653,     0.72638,     0.72604,     0.72418,     0.72263,     0.72234,     0.72056,     0.71966,     0.71941,     0.71806,\n",
       "            0.71706,     0.71593,     0.71484,     0.71422,     0.71341,     0.71251,     0.71203,     0.71073,     0.70956,     0.70673,     0.70452,     0.70397,     0.70335,     0.70192,     0.70132,     0.69992,     0.69828,     0.69766,     0.69581,     0.69426,     0.69343,     0.69284,     0.69046,\n",
       "            0.68965,     0.68874,     0.68822,     0.68695,     0.68524,      0.6832,     0.68064,     0.67863,     0.67662,     0.67599,     0.67604,     0.67485,     0.67386,     0.67332,     0.67245,     0.67092,     0.66907,     0.66662,     0.66563,     0.66483,     0.66373,     0.66272,     0.66108,\n",
       "            0.65977,     0.65741,     0.65509,     0.65309,     0.65161,     0.65111,     0.64956,     0.64776,     0.64662,     0.64482,     0.64293,     0.64288,     0.63969,     0.63563,     0.63183,     0.62941,     0.62679,     0.62454,      0.6232,     0.62143,     0.61907,     0.61711,     0.61447,\n",
       "             0.6137,     0.61239,      0.6115,     0.60979,     0.60862,     0.60632,     0.60552,     0.60332,     0.60036,     0.59745,     0.59451,     0.59175,     0.58927,     0.58823,     0.58586,     0.58385,     0.58239,     0.58028,     0.57903,     0.57723,     0.57343,     0.57186,      0.5709,\n",
       "            0.56839,     0.56538,     0.56313,     0.56046,     0.55842,     0.55369,     0.54959,     0.54812,     0.54662,      0.5422,     0.53803,     0.53347,     0.52788,     0.52525,     0.52351,     0.52039,     0.51837,     0.51554,     0.51194,     0.51009,     0.50498,     0.50136,     0.49752,\n",
       "            0.49339,     0.49198,      0.4899,     0.48355,     0.48005,     0.47603,     0.47513,      0.4704,     0.46711,     0.46518,     0.46052,     0.45547,     0.45239,     0.44888,     0.44507,     0.44222,     0.43821,     0.43534,     0.43036,     0.42455,      0.4176,      0.4135,     0.40793,\n",
       "             0.4019,     0.39426,     0.38769,     0.37877,     0.37589,     0.37197,     0.36666,     0.36242,      0.3593,     0.35303,     0.34841,     0.34396,     0.33626,     0.33148,     0.32748,      0.3252,     0.31974,     0.31235,     0.30912,     0.30528,     0.29957,     0.29225,     0.28919,\n",
       "            0.28543,     0.28104,     0.27793,     0.27186,     0.26448,     0.25934,     0.25327,      0.2474,      0.2444,     0.23991,     0.23608,     0.22906,     0.22588,     0.21746,     0.21387,     0.20723,     0.20506,     0.20167,     0.19573,     0.19193,     0.18777,     0.18506,     0.18368,\n",
       "            0.18061,     0.17801,     0.17427,     0.16803,     0.16329,     0.15932,     0.15438,     0.14982,     0.14452,     0.13894,     0.13242,     0.12926,     0.12854,     0.12365,     0.11896,     0.11673,     0.11429,     0.11153,     0.10737,     0.10297,     0.10056,     0.09834,       0.094,\n",
       "            0.09208,    0.087242,    0.080397,    0.076215,    0.072688,    0.069536,    0.065539,     0.06306,    0.060704,    0.051743,    0.046792,    0.044786,     0.04232,    0.039655,    0.035664,    0.030117,    0.026274,    0.023525,    0.019711,    0.016763,    0.013604,    0.012588,    0.012131,\n",
       "          0.0087585,   0.0054102,   0.0047622,   0.0044712,     0.00418,   0.0033487,   0.0017468,   0.0014499,    0.001153,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.38345,     0.38345,     0.44984,     0.49266,     0.52276,     0.54159,     0.55894,     0.57571,      0.5886,     0.59795,     0.60978,      0.6159,     0.62285,     0.63106,     0.63716,       0.642,     0.64553,     0.65034,     0.65454,      0.6593,     0.66383,     0.66599,     0.66984,\n",
       "            0.67384,     0.67795,     0.68201,     0.68627,     0.69065,     0.69542,     0.69789,     0.70003,     0.70172,     0.70411,     0.70613,     0.70893,     0.70975,     0.71134,     0.71221,     0.71411,     0.71631,     0.71692,     0.71824,     0.71948,     0.72037,     0.72282,     0.72412,\n",
       "            0.72611,     0.72869,     0.72989,     0.73099,     0.73217,     0.73326,     0.73407,     0.73591,     0.73754,     0.73839,     0.74057,      0.7425,     0.74283,     0.74308,     0.74563,     0.74591,     0.74696,     0.74797,     0.74845,     0.75044,     0.75142,     0.75257,     0.75287,\n",
       "             0.7541,     0.75398,     0.75508,     0.75594,     0.75735,     0.75788,     0.75903,      0.7591,     0.75953,     0.76046,     0.76138,     0.76209,     0.76311,     0.76361,     0.76527,     0.76623,     0.76782,     0.76882,     0.76934,     0.76951,     0.77011,     0.77042,     0.77192,\n",
       "            0.77229,     0.77335,     0.77365,     0.77482,     0.77601,     0.77627,     0.77791,     0.77767,     0.77818,     0.77869,     0.77898,     0.77947,     0.77969,     0.78019,     0.78072,     0.78101,     0.78208,     0.78264,     0.78264,     0.78292,     0.78287,     0.78354,     0.78379,\n",
       "            0.78454,     0.78469,     0.78497,     0.78529,     0.78557,     0.78686,      0.7877,     0.78843,     0.78884,     0.78878,     0.78948,      0.7898,      0.7901,     0.79067,     0.79161,      0.7923,     0.79251,     0.79283,     0.79328,     0.79357,     0.79423,      0.7952,     0.79615,\n",
       "            0.79657,     0.79702,     0.79782,     0.79893,     0.79957,     0.80057,     0.80076,     0.80088,     0.80117,     0.80115,     0.80112,      0.8011,     0.80114,     0.80126,     0.80137,     0.80155,     0.80186,     0.80183,      0.8018,     0.80227,     0.80256,     0.80353,     0.80452,\n",
       "             0.8048,     0.80506,     0.80557,     0.80651,     0.80709,     0.80702,     0.80758,     0.80775,     0.80769,     0.80779,     0.80789,     0.80799,     0.80896,     0.80915,     0.81008,     0.81103,     0.81132,     0.81152,     0.81243,     0.81273,     0.81355,     0.81411,     0.81449,\n",
       "            0.81518,     0.81543,     0.81567,     0.81591,     0.81671,     0.81703,     0.81714,     0.81708,     0.81734,     0.81757,     0.81816,     0.81871,     0.81894,     0.81917,     0.82028,     0.82089,     0.82082,     0.82115,     0.82165,     0.82258,      0.8233,      0.8234,     0.82351,\n",
       "            0.82361,     0.82421,     0.82446,     0.82464,     0.82491,     0.82511,     0.82524,     0.82518,     0.82551,     0.82594,     0.82596,     0.82635,     0.82649,     0.82652,     0.82675,     0.82735,     0.82765,     0.82812,     0.82836,     0.82831,     0.82848,     0.82864,     0.82912,\n",
       "            0.82887,     0.82962,     0.82969,      0.8299,     0.83021,     0.83081,     0.83081,     0.83096,     0.83113,     0.83128,     0.83141,     0.83154,     0.83166,     0.83202,     0.83251,     0.83261,      0.8327,      0.8328,      0.8329,     0.83361,      0.8336,     0.83354,     0.83392,\n",
       "            0.83431,     0.83478,     0.83507,     0.83502,     0.83545,     0.83587,     0.83583,     0.83578,     0.83573,     0.83571,     0.83602,     0.83626,      0.8373,     0.83751,     0.83739,     0.83729,     0.83708,     0.83705,     0.83703,     0.83701,     0.83699,     0.83705,     0.83715,\n",
       "            0.83725,     0.83736,     0.83752,     0.83782,      0.8392,     0.83941,     0.83961,     0.83963,      0.8403,     0.84088,      0.8412,     0.84172,     0.84254,     0.84288,     0.84352,     0.84368,      0.8443,     0.84533,      0.8457,      0.8459,      0.8461,     0.84669,     0.84727,\n",
       "            0.84748,     0.84744,     0.84739,     0.84733,     0.84786,     0.84821,     0.84813,     0.84854,     0.84888,     0.85026,     0.85069,     0.85059,      0.8508,     0.85114,     0.85148,     0.85145,     0.85143,     0.85138,     0.85148,     0.85167,     0.85179,     0.85227,     0.85307,\n",
       "            0.85423,     0.85453,     0.85468,     0.85484,     0.85484,      0.8548,     0.85489,     0.85543,       0.856,     0.85644,     0.85711,     0.85711,     0.85738,     0.85803,     0.85817,     0.85831,     0.85841,     0.85837,     0.85833,     0.85826,     0.85862,     0.85857,     0.85854,\n",
       "            0.85851,     0.85863,     0.85885,     0.85911,     0.85943,     0.86042,      0.8604,     0.86037,     0.86035,     0.86052,     0.86116,     0.86136,     0.86151,     0.86166,     0.86166,     0.86163,     0.86161,      0.8616,     0.86158,     0.86157,      0.8619,     0.86197,     0.86181,\n",
       "            0.86176,     0.86231,      0.8625,     0.86269,     0.86257,     0.86251,     0.86246,     0.86243,     0.86238,      0.8627,     0.86338,     0.86359,     0.86379,     0.86419,     0.86507,     0.86517,     0.86515,     0.86513,     0.86516,      0.8661,     0.86654,     0.86652,     0.86749,\n",
       "            0.86747,     0.86745,     0.86743,     0.86806,     0.86833,     0.86831,     0.86829,     0.86825,     0.86842,     0.86862,      0.8688,     0.86897,     0.86909,     0.86996,     0.86992,      0.8703,     0.87021,     0.87019,     0.87049,     0.87049,     0.87036,     0.87031,     0.87023,\n",
       "             0.8702,     0.87017,     0.87013,     0.87003,     0.87026,     0.87046,     0.87158,     0.87194,     0.87191,     0.87188,     0.87236,     0.87232,     0.87282,     0.87314,     0.87331,     0.87328,     0.87325,      0.8732,     0.87399,     0.87466,     0.87519,     0.87511,     0.87498,\n",
       "            0.87494,     0.87541,     0.87535,     0.87531,     0.87577,     0.87568,     0.87636,     0.87683,     0.87719,     0.87763,     0.87763,     0.87779,     0.87795,     0.87855,     0.87855,     0.87866,     0.87877,     0.87888,     0.87899,     0.87993,     0.88056,     0.88053,     0.88074,\n",
       "             0.8817,     0.88189,     0.88238,     0.88232,     0.88237,     0.88374,     0.88395,     0.88402,     0.88394,     0.88378,      0.8837,     0.88386,     0.88414,     0.88408,     0.88462,     0.88483,     0.88505,     0.88527,     0.88533,     0.88528,      0.8856,     0.88568,     0.88599,\n",
       "            0.88615,     0.88657,     0.88683,     0.88754,     0.88782,     0.88848,     0.88838,     0.88887,     0.88937,      0.8893,     0.88982,     0.88978,     0.88963,     0.88975,     0.89026,     0.89114,     0.89106,     0.89099,     0.89149,     0.89144,     0.89126,     0.89113,     0.89103,\n",
       "            0.89088,     0.89084,     0.89078,     0.89058,     0.89046,     0.89037,     0.89089,     0.89161,     0.89192,     0.89233,     0.89249,     0.89238,     0.89233,     0.89228,     0.89223,      0.8922,      0.8924,     0.89269,     0.89333,     0.89373,     0.89421,     0.89417,     0.89413,\n",
       "            0.89467,     0.89517,     0.89511,     0.89533,     0.89554,     0.89596,     0.89614,     0.89668,     0.89664,     0.89717,     0.89951,     0.90017,     0.90044,     0.90211,     0.90198,     0.90235,     0.90247,     0.90266,     0.90292,     0.90349,     0.90343,     0.90336,     0.90333,\n",
       "            0.90326,     0.90323,      0.9032,     0.90317,      0.9037,     0.90386,     0.90422,     0.90419,     0.90474,     0.90467,      0.9046,     0.90503,     0.90558,     0.90599,     0.90616,     0.90613,      0.9067,     0.90667,     0.90669,     0.90707,     0.90717,     0.90713,     0.90751,\n",
       "            0.90755,     0.90806,     0.90801,     0.90851,     0.90966,     0.90958,     0.91003,     0.90992,     0.91024,     0.91037,     0.91024,     0.91022,      0.9102,     0.91042,     0.91132,     0.91118,     0.91114,     0.91137,     0.91165,     0.91159,     0.91155,     0.91142,     0.91138,\n",
       "            0.91251,     0.91302,      0.9132,     0.91413,      0.9143,     0.91535,     0.91522,     0.91566,     0.91683,     0.91679,     0.91667,     0.91724,      0.9172,     0.91702,     0.91732,     0.91809,       0.918,     0.91851,     0.91861,     0.91868,     0.91917,     0.91966,     0.91959,\n",
       "            0.91995,     0.92084,     0.92119,     0.92123,     0.92117,     0.92095,     0.92079,     0.92068,     0.92069,     0.92116,     0.92173,     0.92161,     0.92149,     0.92245,     0.92274,     0.92264,     0.92228,     0.92218,     0.92215,     0.92201,       0.922,      0.9226,     0.92261,\n",
       "            0.92259,     0.92284,      0.9232,     0.92383,     0.92455,     0.92503,     0.92622,      0.9262,     0.92617,     0.92674,      0.9267,     0.92663,      0.9265,     0.92796,     0.92902,     0.92953,     0.93011,     0.93128,     0.93187,     0.93246,      0.9324,       0.933,     0.93287,\n",
       "            0.93284,     0.93276,     0.93267,      0.9331,      0.9332,       0.933,     0.93287,     0.93269,     0.93253,     0.93315,     0.93286,     0.93273,     0.93264,     0.93281,     0.93356,     0.93459,     0.93434,     0.93414,     0.93622,      0.9367,      0.9373,     0.93727,     0.93709,\n",
       "            0.93697,     0.93682,     0.93668,      0.9366,      0.9365,      0.9371,     0.93777,     0.93761,     0.93819,     0.93857,     0.93829,     0.93963,      0.9419,     0.94205,     0.94317,     0.94301,     0.94282,     0.94351,     0.94329,     0.94311,     0.94301,     0.94294,     0.94266,\n",
       "            0.94326,     0.94324,     0.94318,      0.9446,     0.94441,     0.94417,     0.94387,     0.94363,     0.94339,     0.94335,     0.94494,     0.94481,     0.94551,     0.94545,     0.94535,     0.94599,     0.94578,     0.94633,     0.94706,     0.94866,     0.95049,     0.95099,     0.95081,\n",
       "            0.95067,     0.95042,     0.95017,     0.94996,       0.953,     0.95505,      0.9558,     0.95563,     0.95551,     0.95534,     0.95515,     0.95636,      0.9576,     0.95722,     0.95685,     0.95662,     0.95637,     0.95615,     0.95602,     0.95681,     0.95658,     0.95639,     0.95711,\n",
       "            0.95704,     0.95691,     0.95781,     0.95765,     0.95954,     0.96033,     0.96128,     0.96108,     0.96185,     0.96159,     0.96133,     0.96108,     0.96086,      0.9635,     0.96483,     0.96576,     0.96673,     0.96877,     0.96979,      0.9719,     0.97165,     0.97268,     0.97262,\n",
       "            0.97245,       0.975,     0.97562,     0.97665,     0.97653,     0.97626,     0.97602,     0.97766,     0.97831,     0.97933,     0.97911,     0.97887,     0.97858,     0.97843,     0.97834,     0.97817,     0.97939,     0.97924,     0.97904,     0.97894,     0.97866,     0.97846,     0.97825,\n",
       "            0.97834,      0.9804,     0.98069,     0.98036,     0.98017,     0.97996,     0.98032,     0.98118,     0.98101,     0.98246,     0.98223,     0.98359,     0.98344,     0.98347,     0.98475,     0.98463,     0.98445,     0.98432,     0.98409,     0.98559,     0.98529,     0.98511,     0.98671,\n",
       "            0.98647,     0.98809,     0.98785,     0.98749,     0.98738,     0.98722,     0.98699,     0.98681,     0.98667,     0.98639,     0.98844,     0.98826,     0.98794,     0.99016,     0.99002,     0.98993,     0.98973,     0.98944,     0.98932,     0.98916,     0.98892,     0.98859,     0.98846,\n",
       "            0.98828,     0.98807,     0.98791,     0.98761,     0.98721,     0.98692,     0.98657,     0.98621,     0.98602,     0.98572,     0.98546,     0.98648,      0.9923,     0.99197,     0.99182,     0.99152,     0.99142,     0.99561,     0.99546,     0.99536,     0.99525,     0.99518,     0.99514,\n",
       "            0.99505,     0.99497,     0.99485,     0.99464,     0.99447,     0.99432,     0.99413,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.87537,     0.87537,     0.86894,     0.86795,     0.86499,     0.86251,     0.86004,     0.85806,     0.85757,     0.85559,     0.85509,     0.85361,     0.85361,     0.85262,     0.85262,     0.85213,     0.84965,     0.84817,      0.8471,     0.84669,      0.8452,     0.84174,     0.84075,\n",
       "            0.84026,     0.83927,     0.83877,      0.8384,     0.83828,     0.83729,      0.8368,      0.8368,      0.8363,      0.8363,     0.83581,     0.83581,     0.83482,     0.83432,     0.83284,     0.83185,     0.83185,     0.83185,     0.83078,     0.83037,     0.82987,     0.82888,     0.82839,\n",
       "            0.82789,      0.8274,     0.82723,     0.82641,     0.82591,     0.82542,     0.82542,     0.82542,     0.82542,     0.82542,     0.82443,     0.82427,     0.82394,     0.82394,     0.82344,     0.82344,     0.82344,     0.82344,     0.82295,     0.82295,     0.82196,     0.82133,     0.82097,\n",
       "            0.82097,     0.81998,     0.81949,     0.81949,     0.81949,     0.81949,     0.81942,     0.81899,     0.81899,      0.8185,       0.818,     0.81751,     0.81731,     0.81701,     0.81701,     0.81701,     0.81701,     0.81701,     0.81653,     0.81568,     0.81503,     0.81503,     0.81503,\n",
       "            0.81503,     0.81503,     0.81405,     0.81405,     0.81355,     0.81256,     0.81244,     0.81133,     0.81023,      0.8091,     0.80861,     0.80861,     0.80861,     0.80861,     0.80861,     0.80861,     0.80861,     0.80861,     0.80811,     0.80811,     0.80775,     0.80736,     0.80712,\n",
       "            0.80712,     0.80663,     0.80663,     0.80663,     0.80626,     0.80564,     0.80564,     0.80564,     0.80564,     0.80523,     0.80494,     0.80465,     0.80421,     0.80366,     0.80366,     0.80317,     0.80317,     0.80317,     0.80317,     0.80317,     0.80317,     0.80267,     0.80267,\n",
       "            0.80267,     0.80267,     0.80208,     0.80168,     0.80168,     0.80168,     0.80168,     0.80119,      0.8011,     0.80099,     0.80087,     0.80076,     0.80069,     0.80069,     0.80069,     0.80069,     0.80057,     0.80043,     0.80029,      0.8002,      0.7997,     0.79921,     0.79921,\n",
       "            0.79921,     0.79921,     0.79915,     0.79871,     0.79868,     0.79822,     0.79822,      0.7979,     0.79723,     0.79723,     0.79723,     0.79723,     0.79723,     0.79679,     0.79674,     0.79674,     0.79674,     0.79674,     0.79674,     0.79674,     0.79624,     0.79624,     0.79575,\n",
       "            0.79575,     0.79575,     0.79575,     0.79575,     0.79575,     0.79575,     0.79559,     0.79529,     0.79525,     0.79476,     0.79438,     0.79426,     0.79426,     0.79377,     0.79377,     0.79331,     0.79295,     0.79278,     0.79228,     0.79228,     0.79228,     0.79228,     0.79228,\n",
       "            0.79228,     0.79228,     0.79206,     0.79179,     0.79179,     0.79179,      0.7917,     0.79139,      0.7913,      0.7913,     0.79095,     0.79077,     0.79031,     0.78932,     0.78932,     0.78921,     0.78847,     0.78783,     0.78763,     0.78734,     0.78734,     0.78734,     0.78709,\n",
       "            0.78567,     0.78536,     0.78487,     0.78487,     0.78487,     0.78487,      0.7844,     0.78437,     0.78437,     0.78437,     0.78437,     0.78437,     0.78437,     0.78389,     0.78388,     0.78388,     0.78388,     0.78388,     0.78388,     0.78388,     0.78292,     0.78239,     0.78239,\n",
       "            0.78194,      0.7814,     0.78124,       0.781,     0.78091,     0.78081,     0.78055,     0.78028,     0.77999,     0.77893,     0.77893,     0.77893,     0.77881,     0.77744,     0.77675,     0.77619,     0.77499,     0.77486,     0.77475,     0.77464,     0.77453,     0.77448,     0.77448,\n",
       "            0.77448,     0.77448,     0.77448,     0.77448,     0.77448,     0.77448,     0.77448,     0.77421,     0.77399,     0.77349,     0.77349,      0.7732,     0.77274,      0.7725,     0.77201,      0.7714,     0.77102,     0.77036,     0.76954,     0.76954,     0.76954,     0.76954,     0.76954,\n",
       "            0.76946,      0.7692,     0.76891,     0.76858,     0.76855,     0.76831,     0.76781,     0.76756,     0.76756,     0.76706,     0.76643,     0.76583,     0.76558,     0.76558,     0.76553,     0.76537,     0.76522,     0.76496,     0.76409,     0.76387,      0.7636,      0.7636,      0.7636,\n",
       "             0.7636,      0.7636,      0.7636,      0.7636,     0.76305,      0.7628,     0.76261,     0.76261,     0.76261,     0.76261,      0.7624,     0.76162,     0.76162,     0.76162,     0.76162,     0.76162,     0.76157,     0.76133,     0.76106,     0.76062,      0.7599,     0.75957,      0.7594,\n",
       "            0.75922,     0.75915,     0.75915,     0.75915,     0.75915,     0.75914,     0.75898,     0.75882,     0.75867,     0.75816,     0.75816,     0.75816,     0.75816,     0.75816,     0.75777,     0.75758,     0.75749,     0.75739,     0.75729,      0.7572,     0.75717,     0.75665,     0.75566,\n",
       "            0.75533,     0.75519,     0.75519,     0.75519,      0.7543,     0.75388,      0.7536,     0.75341,     0.75309,     0.75272,     0.75272,     0.75272,     0.75271,     0.75223,     0.75223,     0.75213,       0.752,     0.75186,     0.75173,     0.75173,     0.75173,     0.75125,     0.75116,\n",
       "            0.75102,     0.75089,     0.75075,     0.75025,     0.75015,        0.75,     0.74986,     0.74962,     0.74926,     0.74876,     0.74876,     0.74876,     0.74859,     0.74777,     0.74728,     0.74669,     0.74607,      0.7453,      0.7453,     0.74461,     0.74375,     0.74344,      0.7429,\n",
       "            0.74267,     0.74249,     0.74223,     0.74159,     0.74135,     0.74109,     0.74085,     0.74079,     0.74062,     0.74045,     0.74025,     0.73996,     0.73986,     0.73986,     0.73978,     0.73959,     0.73939,     0.73902,     0.73887,     0.73887,     0.73867,     0.73815,     0.73722,\n",
       "            0.73701,     0.73671,     0.73628,     0.73599,     0.73565,     0.73503,     0.73492,     0.73492,     0.73475,     0.73422,     0.73343,     0.73343,     0.73343,     0.73338,     0.73294,     0.73294,     0.73294,     0.73294,     0.73294,     0.73294,     0.73289,     0.73264,     0.73244,\n",
       "            0.73195,     0.73114,      0.7309,     0.73049,     0.72997,     0.72934,     0.72849,     0.72755,     0.72698,     0.72584,     0.72524,     0.72502,     0.72502,      0.7242,     0.72354,     0.72354,     0.72354,     0.72255,     0.72169,     0.72131,     0.72107,     0.72033,     0.72008,\n",
       "            0.71981,       0.719,      0.7186,     0.71815,     0.71761,      0.7171,     0.71638,     0.71598,     0.71562,     0.71517,     0.71497,     0.71466,     0.71358,     0.71266,     0.71266,     0.71254,     0.71196,     0.71146,     0.71105,     0.71066,     0.70935,     0.70843,     0.70769,\n",
       "            0.70659,     0.70628,     0.70584,     0.70444,     0.70353,     0.70277,     0.70277,     0.70227,     0.70227,     0.70227,     0.70206,     0.70126,      0.7009,      0.7005,     0.70019,     0.69997,      0.6998,     0.69941,     0.69881,     0.69881,      0.6981,     0.69783,      0.6975,\n",
       "            0.69683,      0.6968,     0.69585,     0.69585,     0.69585,     0.69585,     0.69559,     0.69534,     0.69501,     0.69471,     0.69436,     0.69436,     0.69288,     0.69279,     0.69174,     0.69139,     0.69105,     0.69041,     0.68991,     0.68984,     0.68935,     0.68884,     0.68859,\n",
       "            0.68804,     0.68778,      0.6876,     0.68735,     0.68686,     0.68645,     0.68634,     0.68612,     0.68595,     0.68522,     0.68468,     0.68447,     0.68348,     0.68348,     0.68296,     0.68266,     0.68244,      0.6822,       0.682,       0.682,     0.68142,     0.68117,     0.68101,\n",
       "            0.67971,     0.67893,     0.67855,     0.67776,     0.67722,     0.67661,     0.67532,     0.67438,     0.67359,     0.67314,     0.67207,     0.67191,     0.67175,     0.67161,     0.67087,     0.66968,     0.66934,     0.66914,     0.66852,     0.66803,     0.66772,      0.6666,     0.66625,\n",
       "            0.66617,     0.66617,     0.66518,     0.66518,      0.6637,     0.66314,     0.66198,     0.66042,     0.65971,     0.65932,     0.65832,     0.65772,     0.65743,     0.65588,      0.6548,     0.65412,     0.65331,     0.65331,     0.65309,     0.65282,      0.6524,     0.65109,     0.65035,\n",
       "            0.65035,      0.6501,     0.64886,     0.64784,     0.64728,     0.64532,     0.64386,     0.64296,     0.64194,     0.64138,     0.64068,     0.63962,     0.63854,     0.63848,     0.63794,     0.63707,     0.63384,     0.63299,     0.63266,     0.63148,     0.63106,     0.63106,      0.6309,\n",
       "            0.63073,     0.63056,     0.63017,     0.62809,     0.62809,      0.6271,     0.62706,     0.62685,     0.62664,      0.6256,     0.62526,     0.62459,     0.62342,     0.62265,     0.62144,     0.61972,     0.61868,     0.61664,     0.61554,     0.61449,     0.61396,     0.61297,     0.61169,\n",
       "            0.61135,     0.61063,     0.60974,      0.6093,     0.60795,     0.60607,     0.60477,     0.60303,     0.60154,     0.60063,     0.59787,     0.59662,     0.59569,     0.59496,     0.59446,     0.59358,      0.5912,     0.58922,     0.58801,     0.58546,     0.58405,     0.58373,     0.58202,\n",
       "            0.58076,     0.57933,     0.57796,     0.57718,     0.57616,     0.57475,     0.57389,     0.57225,     0.57053,     0.56674,       0.564,     0.56281,     0.56122,     0.55935,     0.55819,     0.55648,     0.55447,     0.55344,      0.5512,     0.54931,     0.54831,      0.5476,     0.54473,\n",
       "            0.54352,      0.5424,     0.54178,     0.53973,     0.53769,     0.53526,     0.53221,     0.52984,     0.52746,     0.52671,     0.52628,     0.52487,     0.52347,     0.52283,     0.52181,     0.51978,     0.51762,     0.51453,     0.51314,     0.51173,     0.50989,     0.50856,     0.50668,\n",
       "            0.50519,      0.5025,     0.49985,     0.49759,     0.49505,     0.49392,     0.49194,     0.48992,     0.48865,     0.48665,     0.48454,     0.48417,     0.48025,     0.47579,     0.47163,       0.469,     0.46615,     0.46371,     0.46227,     0.46014,     0.45761,     0.45552,     0.45249,\n",
       "            0.45167,     0.45027,     0.44912,     0.44731,     0.44565,     0.44301,     0.44196,     0.43966,     0.43637,     0.43335,     0.43031,     0.42747,     0.42493,     0.42334,     0.42064,      0.4184,     0.41672,     0.41418,     0.41273,     0.41052,     0.40673,     0.40498,     0.40403,\n",
       "            0.40154,     0.39812,     0.39579,     0.39299,     0.39101,     0.38642,     0.38248,     0.38081,     0.37927,     0.37487,     0.37093,     0.36664,     0.36142,     0.35898,     0.35737,     0.35449,     0.35246,     0.34986,     0.34659,      0.3449,     0.34028,     0.33702,     0.33359,\n",
       "            0.32987,     0.32839,      0.3265,     0.32092,     0.31786,     0.31437,     0.31355,     0.30936,     0.30654,     0.30473,     0.30077,     0.29635,     0.29376,      0.2908,      0.2875,     0.28514,     0.28183,     0.27947,      0.2754,     0.27054,     0.26495,     0.26167,     0.25712,\n",
       "            0.25236,     0.24626,     0.24117,     0.23433,     0.23213,     0.22916,     0.22515,     0.22197,     0.21964,     0.21499,     0.21147,     0.20822,     0.20261,     0.19906,     0.19619,     0.19456,     0.19067,     0.18544,     0.18318,     0.18049,     0.17652,     0.17147,     0.16937,\n",
       "             0.1668,     0.16382,     0.16171,     0.15763,     0.15269,     0.14928,     0.14528,     0.14144,     0.13949,     0.13658,      0.1341,     0.12957,     0.12744,     0.12211,     0.11986,     0.11571,     0.11436,      0.1122,     0.10854,     0.10621,     0.10366,     0.10201,     0.10118,\n",
       "           0.099319,    0.097747,    0.095502,    0.091767,    0.088948,    0.086597,     0.08369,    0.080974,     0.07789,    0.074658,    0.070902,    0.069096,    0.068686,    0.065901,    0.063242,     0.06198,    0.060611,     0.05906,    0.056732,    0.054279,    0.052944,    0.051712,    0.049318,\n",
       "           0.048262,    0.045611,    0.041882,    0.039617,    0.037715,     0.03602,     0.03388,    0.032556,    0.031302,    0.026559,    0.023956,    0.022906,    0.021617,    0.020229,    0.018156,    0.015289,    0.013312,    0.011902,   0.0099534,   0.0084521,   0.0068485,   0.0063339,   0.0061024,\n",
       "          0.0043985,   0.0027124,   0.0023868,   0.0022406,   0.0020944,   0.0016771,  0.00087416,  0.00072549,  0.00057682,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.46180118215470967)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.42005])\n",
       "names: {0: 'Trash'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.8312812758819539), 'metrics/recall(B)': np.float64(0.7843719090009891), 'metrics/mAP50(B)': np.float64(0.8375984615824048), 'metrics/mAP50-95(B)': np.float64(0.4200459288849657), 'fitness': np.float64(0.46180118215470967)}\n",
       "save_dir: PosixPath('/home/ai-laboratory/Documents/ultralytics-floating-trash/runs/detect/yolo12-pt-testing2')\n",
       "speed: {'preprocess': 0.14873152749487417, 'inference': 2.0700982874996043, 'loss': 0.00039067500892997487, 'postprocess': 0.26998600124215955}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val(data=test_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
